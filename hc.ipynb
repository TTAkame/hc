#Hierarchical Clustering

from sklearn.datasets import load_iris
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, r2_score, confusion_matrix, classification_report
from sklearn.linear_model import LogisticRegression
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from scipy.cluster.hierarchy import dendrogram, linkage
from sklearn.cluster import AgglomerativeClustering
from sklearn.decomposition import PCA
from sklearn import metrics


# 1. Data Preprocessing
# Load the dataset
df = pd.read_excel('/content/drive/MyDrive/EEC189/HW3/EastWestAirlines.xlsx')

# Normalize the dataset
df = df.drop('ID#', axis=1)
scaler = MinMaxScaler()
data_norm = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)
plt.figure(figsize=(20, 6)) # change the size as per your requirement
sns.boxplot(data=data_norm)

# 2. Plot the dendrogram
plt.figure()
linked = linkage(data_norm, method='complete')
dendrogram1 = dendrogram(linked)
plt.show()

# 3. Apply Hierarchical Clustering to the dataset
cluster = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='ward')
cluster_labels = cluster.fit_predict(data_norm)

# 4. PCA Variance Explained Plot
pca = PCA().fit(data_norm)
plt.plot(np.cumsum(pca.explained_variance_ratio_))
plt.xlabel('number of components')
plt.ylabel('cumulative explained variance')
plt.show()

# 5. PCA Visualization
pca = PCA(n_components=2)
principalComponents = pca.fit_transform(data_norm)

# Plot the dendrogram on reduced dataset
linked = linkage(principalComponents, method='complete')
dendrogram1 = dendrogram(linked)
plt.show()

# Visualize clusters on the dataset in the reduced 2-dimensional PCA space
plt.scatter(principalComponents[:, 0], principalComponents[:, 1], c=cluster_labels)
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.show()
